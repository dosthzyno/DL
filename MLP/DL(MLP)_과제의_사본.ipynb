{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "DL(MLP)_과제의 사본",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dosthzyno/DL/blob/main/MLP/DL(MLP)_%EA%B3%BC%EC%A0%9C%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MN_pVd5cU2QQ"
      },
      "source": [
        "# 과제: MNIST 데이터를 나만의 NN model로 95 % 이상의 성능으로 training 시켜보자!\n",
        "\n",
        "\n",
        "## Loading MNIST training data\n",
        "\n",
        "출처: 18기 DS 김승하님"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwZNV5MFU2QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c65309-1daf-4bc0-c8ba-eaa92b9becaf"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "# import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "# Loading the data\n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "# Scaling(image data는 min-max scaling 주로 사용)\n",
        "x_train = x_train/255.0\n",
        "x_test = x_test/255.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDU8J2xRU2QQ"
      },
      "source": [
        "## Training Data\n",
        "28 * 28 pixel 값을 가진 총 60000개의 이미지 데이터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVvXmjQSU2QQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3da1b22-b21c-409a-880a-c4f304abdef9"
      },
      "source": [
        "x_train.shape "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "272a9wmbuL3L"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VTAAYKSU2QQ"
      },
      "source": [
        "Neural network 모델에 맞게 이미지 데이터를 벡터 형태로 데이터를 reshape 합니다.  \n",
        "(Model을 만들 때 *keras.layers.Flatten(input_shape=(28, 28)) 이용해도 됨)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq36yUX8U2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0af7b8c-a391-4836-f759-30a44555f7d0"
      },
      "source": [
        "x_train, x_test = x_train.reshape((-1, 28*28)), x_test.reshape((-1, 28*28))\n",
        "x_train.shape, x_test.shape"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 784), (10000, 784))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrQLH9iXU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "c199232a-b765-432a-e4e9-9a824a9dd4c4"
      },
      "source": [
        "# Hint: x_train[0].reshape()\n",
        "plt.imshow(x_train[0].reshape(28, 28)).set_cmap('Greys')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAOTklEQVR4nO3dfYxUZZbH8d8RQVSIQWk7xCHbsxM1MSbTgyVZw0tYxiXIP2AwZkicsJFsT3xJBkPMGDZxfEkMMcuMGM0kPQvCbGYdRwHBxOyihMSQ6GipqIDvpgmNvDRRGSHKLHD2j75MWqx6qqm6Vbfo8/0knaq6p27fQ8GPW3Wfe+sxdxeAke+8ohsA0BqEHQiCsANBEHYgCMIOBHF+Kzc2ceJE7+rqauUmgVD6+vp0+PBhq1RrKOxmNlfSKkmjJP2nu69IPb+rq0vlcrmRTQJIKJVKVWt1v403s1GSnpR0k6RrJC0ys2vq/X0AmquRz+xTJX3i7p+5+98k/UnS/HzaApC3RsJ+haS9Qx73Z8u+w8x6zKxsZuWBgYEGNgegEU0/Gu/uve5ecvdSR0dHszcHoIpGwr5P0uQhj3+QLQPQhhoJ+xuSrjSzH5rZGEk/k7Q5n7YA5K3uoTd3P2Fmd0v6Xw0Ova1x9125dQYgVw2Ns7v7i5JezKkXAE3E6bJAEIQdCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCIOxAEIQdCIKwA0EQdiAIwg4E0dAsrmh/p06dStaPHz/e1O2vW7euau3YsWPJdXfv3p2sP/bYY8n68uXLq9aeeOKJ5LoXXnhhsr5y5cpk/Y477kjWi9BQ2M2sT9LXkk5KOuHupTyaApC/PPbs/+zuh3P4PQCaiM/sQBCNht0lbTGzN82sp9ITzKzHzMpmVh4YGGhwcwDq1WjYp7v7FEk3SbrLzGae+QR373X3kruXOjo6GtwcgHo1FHZ335fdHpK0UdLUPJoCkL+6w25mF5vZ+NP3Jc2RtDOvxgDkq5Gj8Z2SNprZ6d/z3+7+P7l0NcIcOXIkWT958mSy/s477yTrW7ZsqVr76quvkuv29vYm60Xq6upK1pctW5asr169umrtkksuSa47Y8aMZH327NnJejuqO+zu/pmkH+fYC4AmYugNCIKwA0EQdiAIwg4EQdiBILjENQf9/f3Jend3d7L+5Zdf5tnOOeO889L7mtTQmVT7MtQlS5ZUrV1++eXJdceNG5esn4tng7JnB4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgGGfPwWWXXZasd3Z2JuvtPM4+Z86cZL3Wn33Dhg1VaxdccEFy3VmzZiXrODvs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZc1Druuq1a9cm688991yyfsMNNyTrCxcuTNZTpk+fnqxv2rQpWR8zZkyyfuDAgaq1VatWJddFvtizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQ5u4t21ipVPJyudyy7Z0rjh8/nqzXGstevnx51dqjjz6aXHfbtm3J+syZM5N1tJdSqaRyuWyVajX37Ga2xswOmdnOIcsuNbOXzOzj7HZCng0DyN9w3savlTT3jGX3Sdrq7ldK2po9BtDGaobd3V+R9MUZi+dLWpfdXydpQc59AchZvQfoOt19f3b/gKSqX7JmZj1mVjaz8sDAQJ2bA9Coho/G++ARvqpH+dy9191L7l46FyfDA0aKesN+0MwmSVJ2eyi/lgA0Q71h3yxpcXZ/saT0dZAAClfzenYze1rSLEkTzaxf0q8lrZD0ZzNbImmPpFub2eRIV+v702uZMKH+kc/HH388WZ8xY0ayblZxSBdtqGbY3X1RldJPc+4FQBNxuiwQBGEHgiDsQBCEHQiCsANB8FXSI8DSpUur1l5//fXkuhs3bkzWd+3alaxfe+21yTraB3t2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCcfYRIPVV0729vcl1t27dmqzPnz8/WV+wIP31g9OmTatau/nmm5PrcvlsvtizA0EQdiAIwg4EQdiBIAg7EARhB4Ig7EAQTNkcXK3r3efOPXNOz+86cuRI3dtes2ZNsr5w4cJkfdy4cXVve6RqaMpmACMDYQeCIOxAEIQdCIKwA0EQdiAIwg4EwfXswU2dOjVZr/W98ffcc0+y/uyzz1at3X777cl1P/3002T93nvvTdbHjx+frEdTc89uZmvM7JCZ7Ryy7AEz22dmO7Kfec1tE0CjhvM2fq2kSqdR/dbdu7OfF/NtC0Deaobd3V+R9EULegHQRI0coLvbzN7N3uZPqPYkM+sxs7KZlQcGBhrYHIBG1Bv230n6kaRuSfslraz2RHfvdfeSu5c6Ojrq3ByARtUVdnc/6O4n3f2UpN9LSh/SBVC4usJuZpOGPLxZ0s5qzwXQHmpez25mT0uaJWmipIOSfp097pbkkvok/cLd99faGNezjzzffvttsv7aa69Vrd14443JdWv927zllluS9WeeeSZZH4lS17PXPKnG3RdVWLy64a4AtBSnywJBEHYgCMIOBEHYgSAIOxAEl7iiIWPHjk3WZ82aVbU2atSo5LonTpxI1p9//vlk/cMPP6xau/rqq5PrjkTs2YEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMbZkfT5558n6xs2bEjWX3311aq1WuPotVx//fXJ+lVXXdXQ7x9p2LMDQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCMs49wtabcevLJJ5P1p556Klnv7+8/656Gq9b17l1dXcm6WcVvVA6LPTsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBME4+zng6NGjyfoLL7xQtfbQQw8l1/3oo4/q6ikPs2fPTtZXrFiRrF933XV5tjPi1dyzm9lkM9tmZrvNbJeZ/TJbfqmZvWRmH2e3E5rfLoB6Dedt/AlJy9z9Gkn/JOkuM7tG0n2Strr7lZK2Zo8BtKmaYXf3/e7+Vnb/a0nvS7pC0nxJ67KnrZO0oFlNAmjcWR2gM7MuST+R9BdJne6+PysdkNRZZZ0eMyubWbnWedoAmmfYYTezcZLWS1rq7n8dWnN3l+SV1nP3XncvuXupo6OjoWYB1G9YYTez0RoM+h/d/fTXiR40s0lZfZKkQ81pEUAeag692eB1gqslve/uvxlS2ixpsaQV2e2mpnQ4Ahw7dixZ37t3b7J+2223Jetvv/32WfeUlzlz5iTrDz74YNVara+C5hLVfA1nnH2apJ9Les/MdmTLlmsw5H82syWS9ki6tTktAshDzbC7+3ZJ1f6L/Wm+7QBoFk6XBYIg7EAQhB0IgrADQRB2IAgucR2mb775pmpt6dKlyXW3b9+erH/wwQd19ZSHefPmJev3339/st7d3Z2sjx49+qx7QnOwZweCIOxAEIQdCIKwA0EQdiAIwg4EQdiBIMKMs/f19SXrjzzySLL+8ssvV63t2bOnnpZyc9FFF1WtPfzww8l177zzzmR9zJgxdfWE9sOeHQiCsANBEHYgCMIOBEHYgSAIOxAEYQeCCDPOvn79+mR99erVTdv2lClTkvVFixYl6+efn/5r6unpqVobO3Zscl3EwZ4dCIKwA0EQdiAIwg4EQdiBIAg7EARhB4Iwd08/wWyypD9I6pTkknrdfZWZPSDp3yQNZE9d7u4vpn5XqVTycrnccNMAKiuVSiqXyxVnXR7OSTUnJC1z97fMbLykN83spaz2W3f/j7waBdA8w5mffb+k/dn9r83sfUlXNLsxAPk6q8/sZtYl6SeS/pItutvM3jWzNWY2oco6PWZWNrPywMBApacAaIFhh93MxklaL2mpu/9V0u8k/UhStwb3/Csrrefuve5ecvdSR0dHDi0DqMewwm5mozUY9D+6+wZJcveD7n7S3U9J+r2kqc1rE0CjaobdzEzSaknvu/tvhiyfNORpN0vamX97APIynKPx0yT9XNJ7ZrYjW7Zc0iIz69bgcFyfpF80pUMAuRjO0fjtkiqN2yXH1AG0F86gA4Ig7EAQhB0IgrADQRB2IAjCDgRB2IEgCDsQBGEHgiDsQBCEHQiCsANBEHYgCMIOBFHzq6Rz3ZjZgKQ9QxZNlHS4ZQ2cnXbtrV37kuitXnn29g/uXvH731oa9u9t3Kzs7qXCGkho197atS+J3urVqt54Gw8EQdiBIIoOe2/B209p197atS+J3urVkt4K/cwOoHWK3rMDaBHCDgRRSNjNbK6ZfWhmn5jZfUX0UI2Z9ZnZe2a2w8wKnV86m0PvkJntHLLsUjN7ycw+zm4rzrFXUG8PmNm+7LXbYWbzCuptspltM7PdZrbLzH6ZLS/0tUv01ZLXreWf2c1slKSPJP2LpH5Jb0ha5O67W9pIFWbWJ6nk7oWfgGFmMyUdlfQHd782W/aopC/cfUX2H+UEd/9Vm/T2gKSjRU/jnc1WNGnoNOOSFkj6VxX42iX6ulUteN2K2LNPlfSJu3/m7n+T9CdJ8wvoo+25+yuSvjhj8XxJ67L76zT4j6XlqvTWFtx9v7u/ld3/WtLpacYLfe0SfbVEEWG/QtLeIY/71V7zvbukLWb2ppn1FN1MBZ3uvj+7f0BSZ5HNVFBzGu9WOmOa8bZ57eqZ/rxRHKD7vunuPkXSTZLuyt6utiUf/AzWTmOnw5rGu1UqTDP+d0W+dvVOf96oIsK+T9LkIY9/kC1rC+6+L7s9JGmj2m8q6oOnZ9DNbg8V3M/ftdM03pWmGVcbvHZFTn9eRNjfkHSlmf3QzMZI+pmkzQX08T1mdnF24ERmdrGkOWq/qag3S1qc3V8saVOBvXxHu0zjXW2acRX82hU+/bm7t/xH0jwNHpH/VNK/F9FDlb7+UdI72c+uonuT9LQG39b9nwaPbSyRdJmkrZI+lvSypEvbqLf/kvSepHc1GKxJBfU2XYNv0d+VtCP7mVf0a5foqyWvG6fLAkFwgA4IgrADQRB2IAjCDgRB2IEgCDsQBGEHgvh//v1TaNV8b54AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YZXzr-AU2QR"
      },
      "source": [
        "## Training Labels\n",
        "이미지 데이터가 나타내는 숫자값을 label로 가지고 있고, 0부터 9까지의 값을 나타냄  \n",
        "마찬가지로, 60000개의 label이 존재"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-JVvQcJU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375b379b-3b5b-40a1-fdce-7c7f4be2350a"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgAkJK6yU2QR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0c44a21-c514-43f1-9154-83b691bda5d0"
      },
      "source": [
        "# show MNIST label for above data\n",
        "y_train[0]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaI3Kv_GU2QR"
      },
      "source": [
        "## 나만의 모델을 tensorflow keras API 를 이용해 만들어 봅시다~"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSshVnt2U2QS"
      },
      "source": [
        "* parameters for model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "coUZ53nKU2QS"
      },
      "source": [
        "activation_list = [\"sigmoid\", \"relu\", \"softmax\", \"tanh\"]\n",
        "\n",
        "loss_list = [\"sparse_categorical_crossentropy\",\n",
        "             \"categorical_crossentropy\", \n",
        "             \"binary_crossentropy\"]\n",
        "\n",
        "optimizer_list = [\"sgd\", \"adam\", \"rmsprop\", \"adagrad\"]\n",
        "\n",
        "initializer_list = [tf.keras.initializers.RandomNormal(), \n",
        "                    tf.keras.initializers.RandomUniform(), \n",
        "                    tf.keras.initializers.he_normal(), \n",
        "                    tf.keras.initializers.he_uniform(), \n",
        "                    tf.keras.initializers.GlorotUniform(),\n",
        "                    tf.keras.initializers.GlorotNormal()]\n",
        "\n",
        "# dropout\n",
        "dropout_rate = 0.3\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation = \"sigmoid\"),\n",
        "    tf.keras.layers.Dense(2, activation = \"sigmoid\"),\n",
        "    tf.keras.layers.Dropout(dropout_rate)\n",
        "])\n",
        "\n",
        "\n",
        "# regularizer\n",
        "regularizer = tf.keras.regularizers.l1(1e-3)\n",
        "regularizer = tf.keras.regularizers.l2(1e-3)\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
        "                          activity_regularizer=regularizer)\n",
        "])\n",
        "\n",
        "# weight initialization\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(256, input_dim=784, activation=\"sigmoid\",\n",
        "                          kernel_initializer=initializer_list[0])\n",
        "])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-6ZTz4AU2QS"
      },
      "source": [
        "#### My Own Model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziVbGe6sU2QS"
      },
      "source": [
        "#### 자유롭게 Model을 만들고 compile 해봅시다 ####\n",
        "model = tf.keras.Sequential()\n",
        "\n",
        "model.add(keras.Input(shape=(784)))\n",
        "model.add(tf.keras.layers.Dense(1024))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1024))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1024))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1024))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(1024))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.ReLU())\n",
        "\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVhLJHJ9U2QT"
      },
      "source": [
        "내가 만든 모델을 확인해 봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GChgw-8sU2QT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571937b7-df10-47f5-cdf3-e894d99f4e7d"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 1024)              803840    \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 1024)             4096      \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_1 (ReLU)              (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_2 (ReLU)              (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_3 (ReLU)              (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 1024)             4096      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " re_lu_4 (ReLU)              (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                10250     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,032,970\n",
            "Trainable params: 5,022,730\n",
            "Non-trainable params: 10,240\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9zWRRHIU2QT"
      },
      "source": [
        "model을 자유롭게 train 해봅시다.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uygJ19gU2QT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a364a1d-ef3e-4b06-dcaa-3154a290a5a2"
      },
      "source": [
        "model.fit(x_train, y_train, epochs=50)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 23s 11ms/step - loss: 0.2745 - accuracy: 0.9197\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1536 - accuracy: 0.9544\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.1203 - accuracy: 0.9633\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0965 - accuracy: 0.9703\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0830 - accuracy: 0.9748\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0661 - accuracy: 0.9798\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0581 - accuracy: 0.9825\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0500 - accuracy: 0.9844\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0433 - accuracy: 0.9863\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0361 - accuracy: 0.9881\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0335 - accuracy: 0.9888\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0325 - accuracy: 0.9897\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0263 - accuracy: 0.9916\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0264 - accuracy: 0.9916\n",
            "Epoch 15/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0250 - accuracy: 0.9921\n",
            "Epoch 16/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0188 - accuracy: 0.9941\n",
            "Epoch 17/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0202 - accuracy: 0.9937\n",
            "Epoch 18/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0207 - accuracy: 0.9934\n",
            "Epoch 19/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0157 - accuracy: 0.9948\n",
            "Epoch 20/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0166 - accuracy: 0.9946\n",
            "Epoch 21/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0161 - accuracy: 0.9949\n",
            "Epoch 22/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0152 - accuracy: 0.9949\n",
            "Epoch 23/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0126 - accuracy: 0.9959\n",
            "Epoch 24/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0125 - accuracy: 0.9962\n",
            "Epoch 25/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0128 - accuracy: 0.9959\n",
            "Epoch 26/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0126 - accuracy: 0.9964\n",
            "Epoch 27/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0115 - accuracy: 0.9962\n",
            "Epoch 28/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0100 - accuracy: 0.9968\n",
            "Epoch 29/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0125 - accuracy: 0.9957\n",
            "Epoch 30/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0080 - accuracy: 0.9974\n",
            "Epoch 31/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0099 - accuracy: 0.9971\n",
            "Epoch 32/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0087 - accuracy: 0.9972\n",
            "Epoch 33/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0086 - accuracy: 0.9974\n",
            "Epoch 34/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0097 - accuracy: 0.9970\n",
            "Epoch 35/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0084 - accuracy: 0.9972\n",
            "Epoch 36/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0079 - accuracy: 0.9974\n",
            "Epoch 37/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0081 - accuracy: 0.9976\n",
            "Epoch 38/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0080 - accuracy: 0.9974\n",
            "Epoch 39/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0084 - accuracy: 0.9973\n",
            "Epoch 40/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0068 - accuracy: 0.9978\n",
            "Epoch 41/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0073 - accuracy: 0.9979\n",
            "Epoch 42/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0066 - accuracy: 0.9980\n",
            "Epoch 43/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0063 - accuracy: 0.9980\n",
            "Epoch 44/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0067 - accuracy: 0.9980\n",
            "Epoch 45/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0069 - accuracy: 0.9978\n",
            "Epoch 46/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0075 - accuracy: 0.9976\n",
            "Epoch 47/50\n",
            "1875/1875 [==============================] - 20s 11ms/step - loss: 0.0051 - accuracy: 0.9983\n",
            "Epoch 48/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0057 - accuracy: 0.9981\n",
            "Epoch 49/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0068 - accuracy: 0.9980\n",
            "Epoch 50/50\n",
            "1875/1875 [==============================] - 21s 11ms/step - loss: 0.0048 - accuracy: 0.9986\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ad393f110>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8A4zKnEU2QT"
      },
      "source": [
        "95%이상의 성능을 가진 모델을 만들면 완성!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Xz0qGifU2QU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "594b149b-dc31-4b5e-d401-6045c04b3442"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(x_test,y_test, verbose=2)\n",
        "\n",
        "print('\\nAccuracy:', test_acc)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 - 2s - loss: 0.0781 - accuracy: 0.9867 - 2s/epoch - 5ms/step\n",
            "\n",
            "Accuracy: 0.9866999983787537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "EbcuzK_PU2QU"
      },
      "source": [
        "![](https://www.tensorflow.org/versions/master/images/mnist_tensorboard.png)"
      ]
    }
  ]
}